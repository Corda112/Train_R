# ================================================================================
# AQI æ™‚é–“åºåˆ—é æ¸¬æ¨¡å‹è¨“ç·´ - LSTM æ¨¡å‹æ¨¡çµ„ (å„ªåŒ–ç‰ˆ)
# ================================================================================

# è¼‰å…¥å¿…è¦å¥—ä»¶
if(!requireNamespace("torch", quietly = TRUE)) {
  stop("è«‹å®‰è£ torch å¥—ä»¶: install.packages('torch')")
}

if(!requireNamespace("R6", quietly = TRUE)) {
  stop("è«‹å®‰è£ R6 å¥—ä»¶: install.packages('R6')")
}

library(torch)

cat("ğŸ§  è¼‰å…¥ LSTM æ¨¡å‹æ¨¡çµ„ (å„ªåŒ–ç‰ˆ)...\n")

# ================================================================================
# 1. LSTM ç¶²è·¯æ¶æ§‹å®šç¾©
# ================================================================================

#' LSTM ç¶²è·¯æ¨¡çµ„å®šç¾©
#' @param input_size è¼¸å…¥ç‰¹å¾µç¶­åº¦
#' @param hidden_size éš±è—å±¤å¤§å°
#' @param num_layers LSTMå±¤æ•¸
#' @param dropout Dropoutæ¯”ä¾‹
#' @param bidirectional æ˜¯å¦ä½¿ç”¨é›™å‘LSTM
#' @return LSTMç¶²è·¯æ¨¡çµ„
lstm_net <- nn_module(
  "LSTMNet",
  
  initialize = function(input_size, hidden_size = 128, num_layers = 2, 
                       dropout = 0.2, bidirectional = FALSE) {
    self$input_size <- input_size
    self$hidden_size <- hidden_size
    self$num_layers <- num_layers
    self$bidirectional <- bidirectional
    
    # LSTMå±¤
    self$lstm <- nn_lstm(
      input_size = input_size,
      hidden_size = hidden_size,
      num_layers = num_layers,
      dropout = if(num_layers > 1) dropout else 0,
      bidirectional = bidirectional,
      batch_first = TRUE
    )
    
    # è¨ˆç®—LSTMè¼¸å‡ºç¶­åº¦
    lstm_output_size <- if(bidirectional) hidden_size * 2 else hidden_size
    
    # å…¨é€£æ¥å±¤
    self$dropout <- nn_dropout(dropout)
    self$fc1 <- nn_linear(lstm_output_size, hidden_size)
    self$fc2 <- nn_linear(hidden_size, hidden_size %/% 2)
    self$fc3 <- nn_linear(hidden_size %/% 2, 1)
    
    # æ¿€æ´»å‡½æ•¸
    self$relu <- nn_relu()
    self$tanh <- nn_tanh()
  },
  
  forward = function(x) {
    # x: [batch_size, seq_len, input_size]
    
    # LSTMå‰å‘å‚³æ’­
    lstm_out <- self$lstm(x)
    
    # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥çš„è¼¸å‡º
    # lstm_out[[1]]: [batch_size, seq_len, hidden_size * directions]
    seq_len <- dim(lstm_out[[1]])[2]
    last_output <- lstm_out[[1]][, seq_len, ]  # [batch_size, hidden_size * directions]
    
    # å…¨é€£æ¥å±¤
    out <- self$dropout(last_output)
    out <- self$relu(self$fc1(out))
    out <- self$dropout(out)
    out <- self$relu(self$fc2(out))
    out <- self$fc3(out)
    
    return(out)
  }
)

# ================================================================================
# 2. æ—©åœæ©Ÿåˆ¶
# ================================================================================

#' æ—©åœå›èª¿é¡
#' @param patience å®¹å¿è¼ªæ•¸
#' @param min_delta æœ€å°æ”¹å–„å¹…åº¦
#' @param restore_best_weights æ˜¯å¦æ¢å¾©æœ€ä½³æ¬Šé‡
early_stopping <- R6::R6Class(
  "EarlyStopping",
  
  public = list(
    patience = NULL,
    min_delta = NULL,
    restore_best_weights = NULL,
    best_loss = NULL,
    counter = NULL,
    best_weights = NULL,
    
    initialize = function(patience = 15, min_delta = 1e-4, restore_best_weights = TRUE) {
      self$patience <- patience
      self$min_delta <- min_delta
      self$restore_best_weights <- restore_best_weights
      self$best_loss <- Inf
      self$counter <- 0
      self$best_weights <- NULL
    },
    
    check = function(val_loss, model) {
      if(val_loss < self$best_loss - self$min_delta) {
        self$best_loss <- val_loss
        self$counter <- 0
        if(self$restore_best_weights) {
          self$best_weights <- model$state_dict()
        }
        return(FALSE)  # ä¸åœæ­¢
      } else {
        self$counter <- self$counter + 1
        if(self$counter >= self$patience) {
          if(self$restore_best_weights && !is.null(self$best_weights)) {
            model$load_state_dict(self$best_weights)
          }
          return(TRUE)  # åœæ­¢è¨“ç·´
        }
        return(FALSE)
      }
    }
  )
)

# ================================================================================
# 3. å­¸ç¿’ç‡èª¿åº¦å™¨
# ================================================================================

#' å‰µå»ºå­¸ç¿’ç‡èª¿åº¦å™¨
#' @param optimizer å„ªåŒ–å™¨
#' @param scheduler_type èª¿åº¦å™¨é¡å‹
#' @param scheduler_params èª¿åº¦å™¨åƒæ•¸
#' @return å­¸ç¿’ç‡èª¿åº¦å™¨
create_scheduler <- function(optimizer, scheduler_type = "reduce_on_plateau", 
                           scheduler_params = list()) {
  
  if(scheduler_type == "reduce_on_plateau") {
    params <- list(
      factor = 0.5,
      patience = 10,
      min_lr = 1e-6,
      verbose = TRUE
    )
    params[names(scheduler_params)] <- scheduler_params
    
    scheduler <- lr_reduce_on_plateau(
      optimizer,
      factor = params$factor,
      patience = params$patience,
      min_lr = params$min_lr,
      verbose = params$verbose
    )
    
  } else if(scheduler_type == "step") {
    params <- list(
      step_size = 30,
      gamma = 0.1
    )
    params[names(scheduler_params)] <- scheduler_params
    
    scheduler <- lr_step(
      optimizer,
      step_size = params$step_size,
      gamma = params$gamma
    )
    
  } else if(scheduler_type == "cosine") {
    params <- list(
      T_max = 50,
      eta_min = 1e-6
    )
    params[names(scheduler_params)] <- scheduler_params
    
    scheduler <- lr_cosine_annealing(
      optimizer,
      T_max = params$T_max,
      eta_min = params$eta_min
    )
    
  } else {
    stop("ä¸æ”¯æ´çš„èª¿åº¦å™¨é¡å‹: ", scheduler_type)
  }
  
  return(scheduler)
}

# ================================================================================
# 4. è³‡æ–™è¼‰å…¥å™¨
# ================================================================================

#' å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
#' @param dataset AQIè³‡æ–™é›†
#' @param batch_size æ‰¹æ¬¡å¤§å°
#' @param shuffle æ˜¯å¦æ‰“äº‚
#' @param device è¨­å‚™
#' @return è³‡æ–™è¼‰å…¥å™¨
create_dataloader <- function(dataset, batch_size = 256, shuffle = FALSE, device = "cuda") {
  # è½‰æ›ç‚ºå¼µé‡
  x_tensor <- torch_tensor(dataset$x, dtype = torch_float32())$to(device = device)
  y_tensor <- torch_tensor(dataset$y, dtype = torch_float32())$unsqueeze(2)$to(device = device)
  
  # å‰µå»ºTensorDataset
  tensor_dataset <- tensor_dataset(x_tensor, y_tensor)
  
  # å‰µå»ºDataLoader
  dataloader <- dataloader(
    tensor_dataset,
    batch_size = batch_size,
    shuffle = shuffle,
    drop_last = FALSE
  )
  
  return(dataloader)
}

# ================================================================================
# 5. æ··åˆç²¾åº¦è¨“ç·´æ”¯æ´
# ================================================================================

#' æª¢æŸ¥æ˜¯å¦æ”¯æ´æ··åˆç²¾åº¦
#' @param device è¨­å‚™
#' @return æ˜¯å¦æ”¯æ´æ··åˆç²¾åº¦
check_mixed_precision_support <- function(device = "cuda") {
  if(device == "cpu") {
    return(FALSE)
  }
  
      if(!cuda_is_available()) {
    return(FALSE)
  }
  
  # æª¢æŸ¥GPUè¨ˆç®—èƒ½åŠ›
  tryCatch({
    # å˜—è©¦å‰µå»ºGradScaler
    scaler <- torch_amp_grad_scaler()
    return(TRUE)
  }, error = function(e) {
    return(FALSE)
  })
}

# ================================================================================
# 6. LSTM è¨“ç·´å‡½æ•¸ (å„ªåŒ–ç‰ˆ)
# ================================================================================

#' è¨“ç·´ LSTM æ¨¡å‹ (å„ªåŒ–ç‰ˆ)
#' @param train_dataset è¨“ç·´è³‡æ–™é›†
#' @param val_dataset é©—è­‰è³‡æ–™é›†
#' @param params LSTM åƒæ•¸åˆ—è¡¨
#' @param save_checkpoint æ˜¯å¦ä¿å­˜æª¢æŸ¥é»
#' @param checkpoint_path æª¢æŸ¥é»ä¿å­˜è·¯å¾‘
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
#' @return è¨“ç·´å¥½çš„æ¨¡å‹ç‰©ä»¶
train_lstm <- function(train_dataset, val_dataset = NULL, params = LSTM_PARAMS,
                      save_checkpoint = TRUE, checkpoint_path = NULL, verbose = TRUE) {
  
  if(verbose) {
    cat("ğŸ§  é–‹å§‹è¨“ç·´ LSTM æ¨¡å‹...\n")
    cat("è¨“ç·´æ¨£æœ¬æ•¸:", train_dataset$n_windows, "\n")
    if(!is.null(val_dataset)) {
      cat("é©—è­‰æ¨£æœ¬æ•¸:", val_dataset$n_windows, "\n")
    }
    cat("ç‰¹å¾µç¶­åº¦:", train_dataset$n_features, "\n")
    cat("åºåˆ—é•·åº¦:", train_dataset$seq_len, "\n")
  }
  
  start_time <- Sys.time()
  
  # è¨­å®šéš¨æ©Ÿç¨®å­
  torch_manual_seed(RANDOM_SEEDS$torch)
  set.seed(RANDOM_SEEDS$torch)
  
  # è¨­å®šè¨­å‚™
  device <- if(params$device == "cuda" && cuda_is_available()) "cuda" else "cpu"
  if(verbose) {
    cat("ä½¿ç”¨è¨­å‚™:", device, "\n")
    if(device == "cuda") {
              cat("GPU: CUDAè¨­å‚™å¯ç”¨\n")
        # GPUè¨˜æ†¶é«”è³‡è¨Š (ç°¡åŒ–ç‰ˆ)
        tryCatch({
          test_tensor <- torch_randn(100, 100, device = "cuda")
          cat("GPUè¨˜æ†¶é«”: æ­£å¸¸\n")
          rm(test_tensor)
        }, error = function(e) {
          cat("GPUè¨˜æ†¶é«”: æª¢æŸ¥å¤±æ•—\n")
        })
    }
  }
  
  # æª¢æŸ¥æ··åˆç²¾åº¦æ”¯æ´
  use_mixed_precision <- params$mixed_precision && check_mixed_precision_support(device)
  if(verbose && params$mixed_precision) {
    if(use_mixed_precision) {
      cat("âœ… å•Ÿç”¨æ··åˆç²¾åº¦è¨“ç·´\n")
    } else {
      cat("âš ï¸  æ··åˆç²¾åº¦ä¸æ”¯æ´ï¼Œä½¿ç”¨æ¨™æº–ç²¾åº¦\n")
    }
  }
  
  # å‰µå»ºæ¨¡å‹
  model <- lstm_net(
    input_size = train_dataset$n_features,
    hidden_size = params$hidden_size,
    num_layers = params$num_layers,
    dropout = params$dropout,
    bidirectional = params$bidirectional
  )$to(device = device)
  
  if(verbose) {
    cat("æ¨¡å‹åƒæ•¸æ•¸é‡:", sum(sapply(model$parameters, function(p) p$numel())), "\n")
  }
  
  # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
  train_loader <- create_dataloader(
    train_dataset, 
    batch_size = params$batch_size, 
    shuffle = TRUE, 
    device = device
  )
  
  val_loader <- NULL
  if(!is.null(val_dataset)) {
    val_loader <- create_dataloader(
      val_dataset, 
      batch_size = params$batch_size, 
      shuffle = FALSE, 
      device = device
    )
  }
  
  # å‰µå»ºå„ªåŒ–å™¨
  if(params$optimizer == "adam") {
    optimizer <- optim_adam(
      model$parameters,
      lr = params$learning_rate,
      betas = c(params$beta1, params$beta2),
      eps = params$eps,
      weight_decay = params$weight_decay
    )
  } else if(params$optimizer == "adamw") {
    optimizer <- optim_adamw(
      model$parameters,
      lr = params$learning_rate,
      betas = c(params$beta1, params$beta2),
      eps = params$eps,
      weight_decay = params$weight_decay
    )
  } else {
    stop("ä¸æ”¯æ´çš„å„ªåŒ–å™¨: ", params$optimizer)
  }
  
  # å‰µå»ºå­¸ç¿’ç‡èª¿åº¦å™¨
  scheduler <- create_scheduler(
    optimizer,
    scheduler_type = params$scheduler,
    scheduler_params = list(
      factor = params$scheduler_factor,
      patience = params$scheduler_patience,
      min_lr = params$scheduler_min_lr
    )
  )
  
  # å‰µå»ºæå¤±å‡½æ•¸
  criterion <- nn_mse_loss()
  
  # å‰µå»ºæ—©åœæ©Ÿåˆ¶
  early_stop <- early_stopping$new(
    patience = params$patience,
    min_delta = params$min_delta,
    restore_best_weights = TRUE
  )
  
  # å‰µå»ºæ··åˆç²¾åº¦ç¸®æ”¾å™¨
  scaler <- if(use_mixed_precision) torch_amp_grad_scaler() else NULL
  
  # è¨“ç·´æ­·å²è¨˜éŒ„
  train_losses <- numeric(params$epochs)
  val_losses <- numeric(params$epochs)
  learning_rates <- numeric(params$epochs)
  
  # è¨“ç·´å¾ªç’°
  if(verbose) cat("ğŸš€ é–‹å§‹æ¨¡å‹è¨“ç·´...\n")
  
  for(epoch in 1:params$epochs) {
    epoch_start_time <- Sys.time()
    
    # è¨“ç·´éšæ®µ
    model$train()
    train_loss <- 0
    train_batches <- 0
    
    coro::loop(for(batch in train_loader) {
      optimizer$zero_grad()
      
      x_batch <- batch[[1]]
      y_batch <- batch[[2]]
      
      if(use_mixed_precision) {
        # æ··åˆç²¾åº¦å‰å‘å‚³æ’­
        with_autocast(device_type = device, {
          outputs <- model(x_batch)
          loss <- criterion(outputs, y_batch)
        })
        
        # æ··åˆç²¾åº¦åå‘å‚³æ’­
        scaler$scale(loss)$backward()
        scaler$step(optimizer)
        scaler$update()
        
      } else {
        # æ¨™æº–ç²¾åº¦è¨“ç·´
        outputs <- model(x_batch)
        loss <- criterion(outputs, y_batch)
        loss$backward()
        optimizer$step()
      }
      
      train_loss <- train_loss + loss$item()
      train_batches <- train_batches + 1
    })
    
    train_loss <- train_loss / train_batches
    train_losses[epoch] <- train_loss
    
    # é©—è­‰éšæ®µ
    val_loss <- NA
    if(!is.null(val_loader)) {
      model$eval()
      val_loss_sum <- 0
      val_batches <- 0
      
      with_no_grad({
        coro::loop(for(batch in val_loader) {
          x_batch <- batch[[1]]
          y_batch <- batch[[2]]
          
          outputs <- model(x_batch)
          loss <- criterion(outputs, y_batch)
          
          val_loss_sum <- val_loss_sum + loss$item()
          val_batches <- val_batches + 1
        })
      })
      
      val_loss <- val_loss_sum / val_batches
      val_losses[epoch] <- val_loss
      
      # å­¸ç¿’ç‡èª¿åº¦
      if(params$scheduler == "reduce_on_plateau") {
        scheduler$step(val_loss)
      } else {
        scheduler$step()
      }
      
      # æ—©åœæª¢æŸ¥
      if(early_stop$check(val_loss, model)) {
        if(verbose) {
          cat("ğŸ›‘ æ—©åœè§¸ç™¼ï¼Œåœæ­¢è¨“ç·´ (epoch", epoch, ")\n")
        }
        break
      }
    } else {
      scheduler$step()
    }
    
    # è¨˜éŒ„å­¸ç¿’ç‡
    learning_rates[epoch] <- optimizer$param_groups[[1]]$lr
    
    # é¡¯ç¤ºé€²åº¦
    if(verbose && (epoch %% 10 == 0 || epoch == 1)) {
      epoch_time <- as.numeric(difftime(Sys.time(), epoch_start_time, units = "secs"))
      cat(sprintf("Epoch %3d/%d - è¨“ç·´æå¤±: %.6f", epoch, params$epochs, train_loss))
      if(!is.na(val_loss)) {
        cat(sprintf(" - é©—è­‰æå¤±: %.6f", val_loss))
      }
      cat(sprintf(" - å­¸ç¿’ç‡: %.2e - æ™‚é–“: %.1fs\n", learning_rates[epoch], epoch_time))
      
      if(device == "cuda") {
        cat("         GPUè¨˜æ†¶é«”: æ­£å¸¸\n")
      }
    }
    
    # ä¿å­˜æª¢æŸ¥é»
    if(save_checkpoint && !is.null(checkpoint_path) && epoch %% 20 == 0) {
      checkpoint_file <- paste0(checkpoint_path, "_epoch_", epoch, ".pt")
      save_lstm_checkpoint(model, optimizer, epoch, train_loss, val_loss, checkpoint_file)
    }
  }
  
  training_time <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
  
  if(verbose) {
    cat("âœ… LSTM è¨“ç·´å®Œæˆ\n")
    cat("è¨“ç·´æ™‚é–“:", round(training_time, 2), "åˆ†é˜\n")
    cat("æœ€çµ‚è¨“ç·´æå¤±:", round(tail(train_losses[!is.na(train_losses)], 1), 6), "\n")
    if(!is.null(val_dataset)) {
      cat("æœ€çµ‚é©—è­‰æå¤±:", round(tail(val_losses[!is.na(val_losses)], 1), 6), "\n")
      cat("æœ€ä½³é©—è­‰æå¤±:", round(early_stop$best_loss, 6), "\n")
    }
  }
  
  # å‰µå»ºæ¨¡å‹ç‰©ä»¶
  lstm_model <- list(
    model = model,
    training_params = params,
    training_history = list(
      train_losses = train_losses[!is.na(train_losses)],
      val_losses = val_losses[!is.na(val_losses)],
      learning_rates = learning_rates[!is.na(learning_rates)]
    ),
    training_time = training_time,
    best_val_loss = if(!is.null(val_dataset)) early_stop$best_loss else NA,
    data_type = train_dataset$data_type,
    input_size = train_dataset$n_features,
    seq_len = train_dataset$seq_len,
    device = device,
    created_at = Sys.time(),
    model_type = "lstm"
  )
  
  class(lstm_model) <- c("aqi_lstm_model", "list")
  
  # ä¿å­˜æœ€çµ‚æª¢æŸ¥é»
  if(save_checkpoint && !is.null(checkpoint_path)) {
    final_checkpoint <- paste0(checkpoint_path, "_final.pt")
    save_lstm_checkpoint(model, optimizer, epoch, train_loss, val_loss, final_checkpoint)
  }
  
  return(lstm_model)
}

# ================================================================================
# 7. LSTM é æ¸¬å‡½æ•¸
# ================================================================================

#' LSTM æ¨¡å‹é æ¸¬
#' @param lstm_model è¨“ç·´å¥½çš„ LSTM æ¨¡å‹
#' @param test_dataset æ¸¬è©¦è³‡æ–™é›†
#' @param batch_size é æ¸¬æ‰¹æ¬¡å¤§å°
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
#' @return é æ¸¬çµæœå‘é‡
predict_lstm <- function(lstm_model, test_dataset, batch_size = 512, verbose = TRUE) {
  if(!inherits(lstm_model, "aqi_lstm_model")) {
    stop("lstm_model å¿…é ˆæ˜¯ aqi_lstm_model ç‰©ä»¶")
  }
  
  if(verbose) {
    cat("ğŸ”® åŸ·è¡Œ LSTM é æ¸¬...\n")
    cat("æ¸¬è©¦æ¨£æœ¬æ•¸:", test_dataset$n_windows, "\n")
  }
  
  # æª¢æŸ¥ç‰¹å¾µç¶­åº¦ä¸€è‡´æ€§
  if(test_dataset$n_features != lstm_model$input_size) {
    stop("æ¸¬è©¦è³‡æ–™ç‰¹å¾µç¶­åº¦èˆ‡æ¨¡å‹ä¸ä¸€è‡´: ", test_dataset$n_features, " vs ", lstm_model$input_size)
  }
  
  if(test_dataset$seq_len != lstm_model$seq_len) {
    stop("æ¸¬è©¦è³‡æ–™åºåˆ—é•·åº¦èˆ‡æ¨¡å‹ä¸ä¸€è‡´: ", test_dataset$seq_len, " vs ", lstm_model$seq_len)
  }
  
  # å‰µå»ºæ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨
  test_loader <- create_dataloader(
    test_dataset,
    batch_size = batch_size,
    shuffle = FALSE,
    device = lstm_model$device
  )
  
  # é æ¸¬
  lstm_model$model$eval()
  predictions <- c()
  
  with_no_grad({
    coro::loop(for(batch in test_loader) {
      x_batch <- batch[[1]]
      outputs <- lstm_model$model(x_batch)
      batch_predictions <- as.numeric(outputs$cpu())
      predictions <- c(predictions, batch_predictions)
    })
  })
  
  if(verbose) {
    cat("âœ… é æ¸¬å®Œæˆ\n")
    cat("é æ¸¬ç¯„åœ:", round(min(predictions), 2), "~", round(max(predictions), 2), "\n")
  }
  
  return(predictions)
}

# ================================================================================
# 8. GPU è¨˜æ†¶é«”ç®¡ç†
# ================================================================================

#' æ¸…ç†GPUè¨˜æ†¶é«”
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
clear_gpu_memory <- function(verbose = TRUE) {
  if(cuda_is_available()) {
    if(verbose) {
      before_mem <- 0  # GPUè¨˜æ†¶é«”ç›£æ§ç°¡åŒ–
      cat("æ¸…ç†å‰GPUè¨˜æ†¶é«”:", round(before_mem, 2), "GB\n")
    }
    
    # æ¸…ç†å¿«å–
    cuda_empty_cache()
    
    # å¼·åˆ¶åƒåœ¾å›æ”¶
    gc()
    
    if(verbose) {
      after_mem <- 0  # GPUè¨˜æ†¶é«”ç›£æ§ç°¡åŒ–
      cat("æ¸…ç†å¾ŒGPUè¨˜æ†¶é«”:", round(after_mem, 2), "GB\n")
      cat("é‡‹æ”¾è¨˜æ†¶é«”:", round(before_mem - after_mem, 2), "GB\n")
    }
  } else {
    if(verbose) cat("CUDAä¸å¯ç”¨ï¼Œè·³éGPUè¨˜æ†¶é«”æ¸…ç†\n")
  }
}

#' ç›£æ§GPUè¨˜æ†¶é«”ä½¿ç”¨
#' @return GPUè¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š
monitor_gpu_memory <- function() {
  if(!cuda_is_available()) {
    return(list(
      available = FALSE,
      allocated = 0,
      reserved = 0,
      free = 0
    ))
  }
  
  allocated <- 0  # GPUè¨˜æ†¶é«”ç›£æ§ç°¡åŒ–
  reserved <- 0   # GPUè¨˜æ†¶é«”ç›£æ§ç°¡åŒ–
  
  return(list(
    available = TRUE,
    allocated_gb = round(allocated / 1024^3, 2),
    reserved_gb = round(reserved / 1024^3, 2),
    allocated_mb = round(allocated / 1024^2, 1),
    reserved_mb = round(reserved / 1024^2, 1)
  ))
}

# ================================================================================
# 9. æ¨¡å‹ä¿å­˜èˆ‡è¼‰å…¥
# ================================================================================

#' ä¿å­˜ LSTM æ¨¡å‹
#' @param lstm_model LSTM æ¨¡å‹ç‰©ä»¶
#' @param save_path ä¿å­˜è·¯å¾‘ (ä¸å«å‰¯æª”å)
#' @param save_training_history æ˜¯å¦ä¿å­˜è¨“ç·´æ­·å²
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
save_lstm_model <- function(lstm_model, save_path, save_training_history = TRUE, verbose = TRUE) {
  if(!inherits(lstm_model, "aqi_lstm_model")) {
    stop("lstm_model å¿…é ˆæ˜¯ aqi_lstm_model ç‰©ä»¶")
  }
  
  # å‰µå»ºä¿å­˜ç›®éŒ„
  dir.create(dirname(save_path), recursive = TRUE, showWarnings = FALSE)
  
  # ä¿å­˜å®Œæ•´æ¨¡å‹ç‰©ä»¶
  model_path <- paste0(save_path, "_complete.rds")
  saveRDS(lstm_model, model_path)
  
  # ä¿å­˜PyTorchæ¨¡å‹ç‹€æ…‹
  state_path <- paste0(save_path, "_state.pt")
  torch_save(lstm_model$model$state_dict(), state_path)
  
  # ä¿å­˜æ¨¡å‹æ¶æ§‹è³‡è¨Š
  arch_info <- list(
    input_size = lstm_model$input_size,
    hidden_size = lstm_model$training_params$hidden_size,
    num_layers = lstm_model$training_params$num_layers,
    dropout = lstm_model$training_params$dropout,
    bidirectional = lstm_model$training_params$bidirectional
  )
  arch_path <- paste0(save_path, "_architecture.rds")
  saveRDS(arch_info, arch_path)
  
  # ä¿å­˜è¨“ç·´æ­·å²
  if(save_training_history && !is.null(lstm_model$training_history)) {
    history_path <- paste0(save_path, "_history.rds")
    saveRDS(lstm_model$training_history, history_path)
  }
  
  if(verbose) {
    cat("ğŸ’¾ LSTM æ¨¡å‹å·²ä¿å­˜:\n")
    cat("  å®Œæ•´æ¨¡å‹:", basename(model_path), "\n")
    cat("  æ¨¡å‹ç‹€æ…‹:", basename(state_path), "\n")
    cat("  æ¶æ§‹è³‡è¨Š:", basename(arch_path), "\n")
    if(save_training_history) {
      cat("  è¨“ç·´æ­·å²:", basename(history_path), "\n")
    }
  }
}

#' è¼‰å…¥ LSTM æ¨¡å‹
#' @param model_path æ¨¡å‹è·¯å¾‘ (ä¸å«å‰¯æª”å)
#' @param device è¼‰å…¥åˆ°çš„è¨­å‚™
#' @param load_complete æ˜¯å¦è¼‰å…¥å®Œæ•´æ¨¡å‹
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
#' @return LSTM æ¨¡å‹ç‰©ä»¶
load_lstm_model <- function(model_path, device = "cuda", load_complete = TRUE, verbose = TRUE) {
  if(load_complete) {
    complete_path <- paste0(model_path, "_complete.rds")
    if(!file.exists(complete_path)) {
      stop("å®Œæ•´æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: ", complete_path)
    }
    
    lstm_model <- readRDS(complete_path)
    
    # ç§»å‹•æ¨¡å‹åˆ°æŒ‡å®šè¨­å‚™
    if(device != lstm_model$device) {
      lstm_model$model <- lstm_model$model$to(device = device)
      lstm_model$device <- device
    }
    
    if(verbose) {
      cat("ğŸ“¥ è¼‰å…¥å®Œæ•´ LSTM æ¨¡å‹:", basename(complete_path), "\n")
      cat("  è³‡æ–™é¡å‹:", lstm_model$data_type, "\n")
      cat("  è¼¸å…¥ç¶­åº¦:", lstm_model$input_size, "\n")
      cat("  è¨­å‚™:", lstm_model$device, "\n")
      cat("  å‰µå»ºæ™‚é–“:", format(lstm_model$created_at, "%Y-%m-%d %H:%M:%S"), "\n")
    }
    
    return(lstm_model)
    
  } else {
    # è¼‰å…¥æ¶æ§‹å’Œç‹€æ…‹
    arch_path <- paste0(model_path, "_architecture.rds")
    state_path <- paste0(model_path, "_state.pt")
    
    if(!file.exists(arch_path) || !file.exists(state_path)) {
      stop("æ¨¡å‹æ¶æ§‹æˆ–ç‹€æ…‹æª”æ¡ˆä¸å­˜åœ¨")
    }
    
    arch_info <- readRDS(arch_path)
    
    # é‡å»ºæ¨¡å‹
    model <- lstm_net(
      input_size = arch_info$input_size,
      hidden_size = arch_info$hidden_size,
      num_layers = arch_info$num_layers,
      dropout = arch_info$dropout,
      bidirectional = arch_info$bidirectional
    )$to(device = device)
    
    # è¼‰å…¥ç‹€æ…‹
    state_dict <- torch_load(state_path, device = device)
    model$load_state_dict(state_dict)
    
    if(verbose) {
      cat("ğŸ“¥ è¼‰å…¥ LSTM æ¨¡å‹æ¶æ§‹å’Œç‹€æ…‹\n")
      cat("  è¼¸å…¥ç¶­åº¦:", arch_info$input_size, "\n")
      cat("  éš±è—å±¤å¤§å°:", arch_info$hidden_size, "\n")
      cat("  è¨­å‚™:", device, "\n")
    }
    
    return(model)
  }
}

# ================================================================================
# 10. æª¢æŸ¥é»åŠŸèƒ½
# ================================================================================

#' ä¿å­˜ LSTM æª¢æŸ¥é»
#' @param model LSTM æ¨¡å‹
#' @param optimizer å„ªåŒ–å™¨
#' @param epoch ç•¶å‰è¼ªæ•¸
#' @param train_loss è¨“ç·´æå¤±
#' @param val_loss é©—è­‰æå¤±
#' @param checkpoint_path æª¢æŸ¥é»è·¯å¾‘
save_lstm_checkpoint <- function(model, optimizer, epoch, train_loss, val_loss, checkpoint_path) {
  dir.create(dirname(checkpoint_path), recursive = TRUE, showWarnings = FALSE)
  
  checkpoint <- list(
    model_state_dict = model$state_dict(),
    optimizer_state_dict = optimizer$state_dict(),
    epoch = epoch,
    train_loss = train_loss,
    val_loss = val_loss,
    timestamp = Sys.time()
  )
  
  torch_save(checkpoint, checkpoint_path)
}

#' è¼‰å…¥ LSTM æª¢æŸ¥é»
#' @param checkpoint_path æª¢æŸ¥é»è·¯å¾‘
#' @param model LSTM æ¨¡å‹
#' @param optimizer å„ªåŒ–å™¨ (å¯é¸)
#' @param device è¨­å‚™
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
#' @return æª¢æŸ¥é»è³‡è¨Š
load_lstm_checkpoint <- function(checkpoint_path, model, optimizer = NULL, device = "cuda", verbose = TRUE) {
  if(!file.exists(checkpoint_path)) {
    stop("æª¢æŸ¥é»æª”æ¡ˆä¸å­˜åœ¨: ", checkpoint_path)
  }
  
  checkpoint <- torch_load(checkpoint_path, device = device)
  
  model$load_state_dict(checkpoint$model_state_dict)
  
  if(!is.null(optimizer)) {
    optimizer$load_state_dict(checkpoint$optimizer_state_dict)
  }
  
  if(verbose) {
    cat("ğŸ“¥ è¼‰å…¥ LSTM æª¢æŸ¥é»:", basename(checkpoint_path), "\n")
    cat("  è¼ªæ•¸:", checkpoint$epoch, "\n")
    cat("  è¨“ç·´æå¤±:", round(checkpoint$train_loss, 6), "\n")
    if(!is.na(checkpoint$val_loss)) {
      cat("  é©—è­‰æå¤±:", round(checkpoint$val_loss, 6), "\n")
    }
    cat("  æ™‚é–“æˆ³:", format(checkpoint$timestamp, "%Y-%m-%d %H:%M:%S"), "\n")
  }
  
  return(checkpoint)
}

# ================================================================================
# 11. å·¥å…·å‡½æ•¸
# ================================================================================

#' æª¢æŸ¥ LSTM æ¨¡å‹å¥åº·ç‹€æ…‹
#' @param lstm_model LSTM æ¨¡å‹ç‰©ä»¶
#' @return å¥åº·æª¢æŸ¥çµæœ
check_lstm_model_health <- function(lstm_model) {
  if(!inherits(lstm_model, "aqi_lstm_model")) {
    return(list(is_healthy = FALSE, issues = "ä¸æ˜¯æœ‰æ•ˆçš„ aqi_lstm_model ç‰©ä»¶"))
  }
  
  issues <- c()
  
  # æª¢æŸ¥å¿…è¦çµ„ä»¶
  required_components <- c("model", "training_params", "input_size", "seq_len")
  missing_components <- setdiff(required_components, names(lstm_model))
  if(length(missing_components) > 0) {
    issues <- c(issues, paste("ç¼ºå°‘çµ„ä»¶:", paste(missing_components, collapse = ", ")))
  }
  
  # æª¢æŸ¥æ¨¡å‹ç‰©ä»¶
  if(is.null(lstm_model$model)) {
    issues <- c(issues, "æ¨¡å‹ç‰©ä»¶ç‚ºç©º")
  }
  
  # æª¢æŸ¥è¨­å‚™ä¸€è‡´æ€§
  if(!is.null(lstm_model$model) && !is.null(lstm_model$device)) {
    tryCatch({
      # å˜—è©¦ç²å–æ¨¡å‹åƒæ•¸çš„è¨­å‚™
      model_device <- lstm_model$model$parameters[[1]]$device$type
      if(model_device != lstm_model$device) {
        issues <- c(issues, "æ¨¡å‹è¨­å‚™èˆ‡è¨˜éŒ„çš„è¨­å‚™ä¸ä¸€è‡´")
      }
    }, error = function(e) {
      issues <- c(issues, "ç„¡æ³•æª¢æŸ¥æ¨¡å‹è¨­å‚™")
    })
  }
  
  is_healthy <- length(issues) == 0
  
  return(list(
    is_healthy = is_healthy,
    issues = if(length(issues) > 0) issues else "æ¨¡å‹ç‹€æ…‹è‰¯å¥½"
  ))
}

#' ç²å–æ¨¡å‹æ‘˜è¦è³‡è¨Š
#' @param lstm_model LSTM æ¨¡å‹ç‰©ä»¶
#' @return æ¨¡å‹æ‘˜è¦
get_lstm_model_summary <- function(lstm_model) {
  if(!inherits(lstm_model, "aqi_lstm_model")) {
    stop("lstm_model å¿…é ˆæ˜¯ aqi_lstm_model ç‰©ä»¶")
  }
  
  # è¨ˆç®—åƒæ•¸æ•¸é‡
  total_params <- sum(sapply(lstm_model$model$parameters, function(p) p$numel()))
  trainable_params <- sum(sapply(lstm_model$model$parameters[sapply(lstm_model$model$parameters, function(p) p$requires_grad)], function(p) p$numel()))
  
  summary <- list(
    model_type = "LSTM",
    data_type = lstm_model$data_type,
    input_size = lstm_model$input_size,
    seq_len = lstm_model$seq_len,
    hidden_size = lstm_model$training_params$hidden_size,
    num_layers = lstm_model$training_params$num_layers,
    bidirectional = lstm_model$training_params$bidirectional,
    total_params = total_params,
    trainable_params = trainable_params,
    device = lstm_model$device,
    training_time = lstm_model$training_time,
    best_val_loss = lstm_model$best_val_loss,
    created_at = lstm_model$created_at
  )
  
  return(summary)
}

cat("âœ… LSTM æ¨¡å‹æ¨¡çµ„ (å„ªåŒ–ç‰ˆ) è¼‰å…¥å®Œæˆ\n") 