# ================================================================================
# AQI æ™‚é–“åºåˆ—é æ¸¬æ¨¡å‹è¨“ç·´ - LSTM æ¨¡çµ„
# ================================================================================

# è¼‰å…¥å¿…è¦å¥—ä»¶
if(!requireNamespace("torch", quietly = TRUE)) {
  stop("è«‹å®‰è£ torch å¥—ä»¶: install.packages('torch')")
}

cat("ğŸ§  è¼‰å…¥ LSTM æ¨¡å‹æ¨¡çµ„...\n")

# ================================================================================
# 1. LSTM ç¶²è·¯æ¶æ§‹å®šç¾©
# ================================================================================

#' å®šç¾©LSTMç¶²è·¯æ¶æ§‹
#' @param n_features è¼¸å…¥ç‰¹å¾µæ•¸
#' @param hidden_size éš±è—å±¤å¤§å°
#' @param num_layers LSTMå±¤æ•¸
#' @param dropout Dropoutæ¯”ä¾‹
#' @param bidirectional æ˜¯å¦ä½¿ç”¨é›™å‘LSTM
#' @return LSTMç¶²è·¯æ¨¡çµ„
lstm_net <- torch::nn_module(
  "LSTMNet",
  
  initialize = function(n_features, hidden_size = 128, num_layers = 2, 
                       dropout = 0.2, bidirectional = FALSE) {
    self$n_features <- n_features
    self$hidden_size <- hidden_size
    self$num_layers <- num_layers
    self$bidirectional <- bidirectional
    
    # LSTMå±¤
    self$lstm <- torch::nn_lstm(
      input_size = n_features,
      hidden_size = hidden_size,
      num_layers = num_layers,
      dropout = dropout,
      batch_first = TRUE,
      bidirectional = bidirectional
    )
    
    # è¨ˆç®—LSTMè¼¸å‡ºç¶­åº¦
    lstm_output_size <- ifelse(bidirectional, hidden_size * 2, hidden_size)
    
    # å…¨é€£æ¥å±¤
    self$fc1 <- torch::nn_linear(lstm_output_size, hidden_size)
    self$dropout <- torch::nn_dropout(dropout)
    self$fc2 <- torch::nn_linear(hidden_size, 1)
    
    # æ¿€æ´»å‡½æ•¸
    self$relu <- torch::nn_relu()
  },
  
  forward = function(x) {
    # x: [batch_size, seq_len, n_features]
    
    # LSTMå‰å‘å‚³æ’­
    lstm_out <- self$lstm(x)
    
    # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥çš„è¼¸å‡º
    # lstm_out[[1]]: [batch_size, seq_len, hidden_size * directions]
    last_output <- lstm_out[[1]][, -1, ]  # [batch_size, hidden_size * directions]
    
    # å…¨é€£æ¥å±¤
    out <- self$fc1(last_output)
    out <- self$relu(out)
    out <- self$dropout(out)
    out <- self$fc2(out)
    
    return(out)
  }
)

#' å‰µå»ºLSTMæ¨¡å‹
#' @param n_features è¼¸å…¥ç‰¹å¾µæ•¸
#' @param params LSTMåƒæ•¸åˆ—è¡¨
#' @return LSTMæ¨¡å‹å¯¦ä¾‹
create_lstm_model <- function(n_features, params = LSTM_PARAMS) {
  model <- lstm_net(
    n_features = n_features,
    hidden_size = params$hidden_size,
    num_layers = params$num_layers,
    dropout = params$dropout,
    bidirectional = params$bidirectional
  )
  
  return(model)
}

# ================================================================================
# 2. è³‡æ–™é è™•ç†å‡½æ•¸
# ================================================================================

#' å°‡è³‡æ–™é›†è½‰æ›ç‚ºtorchå¼µé‡
#' @param dataset aqi_dataset ç‰©ä»¶
#' @param device è¨­å‚™ ("cpu", "cuda")
#' @return torchå¼µé‡åˆ—è¡¨
dataset_to_torch <- function(dataset, device = "cpu") {
  if(!inherits(dataset, "aqi_dataset")) {
    stop("dataset å¿…é ˆæ˜¯ aqi_dataset ç‰©ä»¶")
  }
  
  # è½‰æ›ç‚ºtorchå¼µé‡
  x_tensor <- torch::torch_tensor(dataset$x, dtype = torch::torch_float32())
  y_tensor <- torch::torch_tensor(dataset$y, dtype = torch::torch_float32())
  
  # ç§»å‹•åˆ°æŒ‡å®šè¨­å‚™
  if(device != "cpu") {
    x_tensor <- x_tensor$to(device = device)
    y_tensor <- y_tensor$to(device = device)
  }
  
  return(list(x = x_tensor, y = y_tensor))
}

#' å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
#' @param dataset aqi_dataset ç‰©ä»¶
#' @param batch_size æ‰¹æ¬¡å¤§å°
#' @param shuffle æ˜¯å¦æ‰“äº‚
#' @param device è¨­å‚™
#' @return torchè³‡æ–™è¼‰å…¥å™¨
create_dataloader <- function(dataset, batch_size = 256, shuffle = TRUE, device = "cpu") {
  # è½‰æ›ç‚ºtorchå¼µé‡
  torch_data <- dataset_to_torch(dataset, device = device)
  
  # å‰µå»ºTensorDataset
  tensor_dataset <- torch::tensor_dataset(torch_data$x, torch_data$y)
  
  # å‰µå»ºDataLoader
  dataloader <- torch::dataloader(
    dataset = tensor_dataset,
    batch_size = batch_size,
    shuffle = shuffle,
    drop_last = FALSE
  )
  
  return(dataloader)
}

# ================================================================================
# 3. è¨“ç·´å‡½æ•¸
# ================================================================================

#' è¨“ç·´LSTMæ¨¡å‹
#' @param train_dataset è¨“ç·´è³‡æ–™é›†
#' @param val_dataset é©—è­‰è³‡æ–™é›† (å¯é¸)
#' @param params LSTMåƒæ•¸åˆ—è¡¨
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
#' @return è¨“ç·´å¥½çš„æ¨¡å‹ç‰©ä»¶
train_lstm <- function(train_dataset, val_dataset = NULL, params = LSTM_PARAMS, verbose = TRUE) {
  if(!inherits(train_dataset, "aqi_dataset")) {
    stop("train_dataset å¿…é ˆæ˜¯ aqi_dataset ç‰©ä»¶")
  }
  
  if(verbose) {
    cat("ğŸ§  é–‹å§‹è¨“ç·´ LSTM æ¨¡å‹...\n")
    cat("  è¨“ç·´æ¨£æœ¬æ•¸:", format(train_dataset$n_windows, big.mark = ","), "\n")
    cat("  ç‰¹å¾µæ•¸é‡:", train_dataset$n_features, "\n")
    cat("  åºåˆ—é•·åº¦:", train_dataset$seq_len, "\n")
  }
  
  start_time <- Sys.time()
  
  # æª¢æŸ¥è¨­å‚™å¯ç”¨æ€§
  device <- params$device
  if(device == "cuda" && !torch::cuda_is_available()) {
    warning("CUDAä¸å¯ç”¨ï¼Œåˆ‡æ›åˆ°CPU")
    device <- "cpu"
  }
  
  if(verbose) {
    cat("  ä½¿ç”¨è¨­å‚™:", device, "\n")
    if(device == "cuda") {
      cat("  GPUè¨˜æ†¶é«”:", round(torch::cuda_memory_allocated() / 1024^3, 2), "GB\n")
    }
  }
  
  # å‰µå»ºæ¨¡å‹
  model <- create_lstm_model(train_dataset$n_features, params)
  model <- model$to(device = device)
  
  if(verbose) {
    cat("  æ¨¡å‹åƒæ•¸æ•¸é‡:", sum(sapply(model$parameters, function(p) p$numel())), "\n")
  }
  
  # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
  train_loader <- create_dataloader(
    train_dataset, 
    batch_size = params$batch_size, 
    shuffle = TRUE, 
    device = device
  )
  
  val_loader <- NULL
  if(!is.null(val_dataset)) {
    if(!inherits(val_dataset, "aqi_dataset")) {
      stop("val_dataset å¿…é ˆæ˜¯ aqi_dataset ç‰©ä»¶")
    }
    
    val_loader <- create_dataloader(
      val_dataset, 
      batch_size = params$batch_size, 
      shuffle = FALSE, 
      device = device
    )
    
    if(verbose) {
      cat("  é©—è­‰æ¨£æœ¬æ•¸:", format(val_dataset$n_windows, big.mark = ","), "\n")
    }
  }
  
  # è¨­å®šå„ªåŒ–å™¨
  if(params$optimizer == "adam") {
    optimizer <- torch::optim_adam(
      model$parameters,
      lr = params$learning_rate,
      betas = c(params$beta1, params$beta2),
      eps = params$eps,
      weight_decay = params$weight_decay
    )
  } else {
    stop("ä¸æ”¯æ´çš„å„ªåŒ–å™¨: ", params$optimizer)
  }
  
  # è¨­å®šæå¤±å‡½æ•¸
  criterion <- torch::nn_mse_loss()
  
  # è¨­å®šå­¸ç¿’ç‡èª¿åº¦å™¨
  scheduler <- NULL
  if(params$scheduler == "reduce_on_plateau") {
    scheduler <- torch::lr_reduce_on_plateau(
      optimizer,
      mode = "min",
      factor = params$scheduler_factor,
      patience = params$scheduler_patience,
      min_lr = params$scheduler_min_lr
    )
  }
  
  # è¨­å®šæ··åˆç²¾åº¦è¨“ç·´
  scaler <- NULL
  if(params$mixed_precision && device == "cuda") {
    scaler <- torch::cuda_amp_grad_scaler()
    if(verbose) {
      cat("  å•Ÿç”¨æ··åˆç²¾åº¦è¨“ç·´\n")
    }
  }
  
  # è¨“ç·´æ­·å²è¨˜éŒ„
  train_losses <- c()
  val_losses <- c()
  best_val_loss <- Inf
  patience_counter <- 0
  best_model_state <- NULL
  
  if(verbose) {
    cat("  é–‹å§‹è¨“ç·´...\n")
  }
  
  # è¨“ç·´å¾ªç’°
  for(epoch in 1:params$epochs) {
    # è¨“ç·´éšæ®µ
    model$train()
    train_loss <- 0
    n_train_batches <- 0
    
    # ç°¡åŒ–çš„è¨“ç·´å¾ªç’° (é¿å…ä½¿ç”¨coro)
    train_iter <- torch::dataloader_make_iter(train_loader)
    repeat {
      batch <- torch::dataloader_next(train_iter)
      if(is.null(batch)) break
      
      optimizer$zero_grad()
      
      x_batch <- batch[[1]]
      y_batch <- batch[[2]]$view(c(-1, 1))
      
      if(!is.null(scaler)) {
        # æ··åˆç²¾åº¦è¨“ç·´
        with(torch::autocast(device_type = "cuda"), {
          outputs <- model(x_batch)
          loss <- criterion(outputs, y_batch)
        })
        
        scaler$scale(loss)$backward()
        scaler$step(optimizer)
        scaler$update()
      } else {
        # æ¨™æº–è¨“ç·´
        outputs <- model(x_batch)
        loss <- criterion(outputs, y_batch)
        
        loss$backward()
        optimizer$step()
      }
      
      train_loss <- train_loss + loss$item()
      n_train_batches <- n_train_batches + 1
    }
    
    avg_train_loss <- train_loss / n_train_batches
    train_losses <- c(train_losses, avg_train_loss)
    
    # é©—è­‰éšæ®µ
    avg_val_loss <- NULL
    if(!is.null(val_loader)) {
      model$eval()
      val_loss <- 0
      n_val_batches <- 0
      
      with(torch::no_grad(), {
        val_iter <- torch::dataloader_make_iter(val_loader)
        repeat {
          batch <- torch::dataloader_next(val_iter)
          if(is.null(batch)) break
          
          x_batch <- batch[[1]]
          y_batch <- batch[[2]]$view(c(-1, 1))
          
          outputs <- model(x_batch)
          loss <- criterion(outputs, y_batch)
          
          val_loss <- val_loss + loss$item()
          n_val_batches <- n_val_batches + 1
        }
      })
      
      avg_val_loss <- val_loss / n_val_batches
      val_losses <- c(val_losses, avg_val_loss)
      
      # Early stoppingæª¢æŸ¥
      if(avg_val_loss < best_val_loss - params$min_delta) {
        best_val_loss <- avg_val_loss
        patience_counter <- 0
        best_model_state <- model$state_dict()
      } else {
        patience_counter <- patience_counter + 1
      }
      
      # å­¸ç¿’ç‡èª¿åº¦
      if(!is.null(scheduler)) {
        scheduler$step(avg_val_loss)
      }
    }
    
    # é¡¯ç¤ºé€²åº¦
    if(verbose && (epoch %% 10 == 0 || epoch == 1)) {
      cat("  Epoch", epoch, "/", params$epochs, 
          "- è¨“ç·´æå¤±:", round(avg_train_loss, 6))
      if(!is.null(avg_val_loss)) {
        cat(", é©—è­‰æå¤±:", round(avg_val_loss, 6))
      }
      cat("\n")
    }
    
    # Early stopping
    if(!is.null(val_loader) && patience_counter >= params$patience) {
      if(verbose) {
        cat("  Early stopping at epoch", epoch, "\n")
      }
      break
    }
    
    # GPUè¨˜æ†¶é«”æ¸…ç†
    if(device == "cuda" && epoch %% 50 == 0) {
      torch::cuda_empty_cache()
    }
  }
  
  # è¼‰å…¥æœ€ä½³æ¨¡å‹
  if(!is.null(best_model_state)) {
    model$load_state_dict(best_model_state)
    if(verbose) {
      cat("  è¼‰å…¥æœ€ä½³æ¨¡å‹ (é©—è­‰æå¤±:", round(best_val_loss, 6), ")\n")
    }
  }
  
  end_time <- Sys.time()
  training_time <- as.numeric(difftime(end_time, start_time, units = "mins"))
  
  if(verbose) {
    cat("âœ… æ¨¡å‹è¨“ç·´å®Œæˆ\n")
    cat("  è¨“ç·´æ™‚é–“:", round(training_time, 2), "åˆ†é˜\n")
    cat("  æœ€çµ‚è¨“ç·´æå¤±:", round(tail(train_losses, 1), 6), "\n")
    if(length(val_losses) > 0) {
      cat("  æœ€çµ‚é©—è­‰æå¤±:", round(tail(val_losses, 1), 6), "\n")
      cat("  æœ€ä½³é©—è­‰æå¤±:", round(best_val_loss, 6), "\n")
    }
  }
  
  # å‰µå»ºæ¨¡å‹åŒ…è£ç‰©ä»¶
  lstm_model <- list(
    model = model,
    n_features = train_dataset$n_features,
    seq_len = train_dataset$seq_len,
    data_type = train_dataset$data_type,
    params = params,
    device = device,
    training_time = training_time,
    train_losses = train_losses,
    val_losses = val_losses,
    best_val_loss = best_val_loss,
    trained_at = end_time
  )
  
  class(lstm_model) <- c("aqi_lstm_model", "list")
  
  return(lstm_model)
}

#' æ‰“å°LSTMæ¨¡å‹æ‘˜è¦
#' @param x aqi_lstm_model ç‰©ä»¶
print.aqi_lstm_model <- function(x, ...) {
  cat("AQI LSTM æ¨¡å‹\n")
  cat("==============\n")
  cat("è³‡æ–™é¡å‹:", x$data_type, "\n")
  cat("ç‰¹å¾µæ•¸é‡:", x$n_features, "\n")
  cat("åºåˆ—é•·åº¦:", x$seq_len, "\n")
  cat("è¨­å‚™:", x$device, "\n")
  cat("è¨“ç·´æ™‚é–“:", round(x$training_time, 2), "åˆ†é˜\n")
  cat("è¨“ç·´æ™‚é–“:", format(x$trained_at, "%Y-%m-%d %H:%M:%S"), "\n")
  
  # é¡¯ç¤ºä¸»è¦åƒæ•¸
  cat("\nä¸»è¦åƒæ•¸:\n")
  cat("  éš±è—å±¤å¤§å°:", x$params$hidden_size, "\n")
  cat("  LSTMå±¤æ•¸:", x$params$num_layers, "\n")
  cat("  Dropout:", x$params$dropout, "\n")
  cat("  å­¸ç¿’ç‡:", x$params$learning_rate, "\n")
  cat("  æ‰¹æ¬¡å¤§å°:", x$params$batch_size, "\n")
  
  # é¡¯ç¤ºè¨“ç·´çµæœ
  cat("\nè¨“ç·´çµæœ:\n")
  cat("  æœ€çµ‚è¨“ç·´æå¤±:", round(tail(x$train_losses, 1), 6), "\n")
  if(length(x$val_losses) > 0) {
    cat("  æœ€çµ‚é©—è­‰æå¤±:", round(tail(x$val_losses, 1), 6), "\n")
    cat("  æœ€ä½³é©—è­‰æå¤±:", round(x$best_val_loss, 6), "\n")
  }
}

# ================================================================================
# 4. é æ¸¬å‡½æ•¸
# ================================================================================

#' ä½¿ç”¨LSTMæ¨¡å‹é€²è¡Œé æ¸¬
#' @param model aqi_lstm_model ç‰©ä»¶
#' @param test_dataset æ¸¬è©¦è³‡æ–™é›†
#' @param batch_size é æ¸¬æ‰¹æ¬¡å¤§å°
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
#' @return é æ¸¬çµæœå‘é‡
predict_lstm <- function(model, test_dataset, batch_size = NULL, verbose = TRUE) {
  if(!inherits(model, "aqi_lstm_model")) {
    stop("model å¿…é ˆæ˜¯ aqi_lstm_model ç‰©ä»¶")
  }
  
  if(!inherits(test_dataset, "aqi_dataset")) {
    stop("test_dataset å¿…é ˆæ˜¯ aqi_dataset ç‰©ä»¶")
  }
  
  if(verbose) {
    cat("ğŸ”® ä½¿ç”¨ LSTM æ¨¡å‹é€²è¡Œé æ¸¬...\n")
    cat("  æ¸¬è©¦æ¨£æœ¬æ•¸:", format(test_dataset$n_windows, big.mark = ","), "\n")
  }
  
  # æª¢æŸ¥ç‰¹å¾µä¸€è‡´æ€§
  if(test_dataset$n_features != model$n_features) {
    stop("æ¸¬è©¦è³‡æ–™çš„ç‰¹å¾µæ•¸èˆ‡æ¨¡å‹ä¸ä¸€è‡´")
  }
  
  if(test_dataset$seq_len != model$seq_len) {
    stop("æ¸¬è©¦è³‡æ–™çš„åºåˆ—é•·åº¦èˆ‡æ¨¡å‹ä¸ä¸€è‡´")
  }
  
  # è¨­å®šæ‰¹æ¬¡å¤§å°
  if(is.null(batch_size)) {
    batch_size <- model$params$batch_size
  }
  
  # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
  test_loader <- create_dataloader(
    test_dataset, 
    batch_size = batch_size, 
    shuffle = FALSE, 
    device = model$device
  )
  
  # é æ¸¬
  model$model$eval()
  predictions <- c()
  
  with(torch::no_grad(), {
    test_iter <- torch::dataloader_make_iter(test_loader)
    repeat {
      batch <- torch::dataloader_next(test_iter)
      if(is.null(batch)) break
      
      x_batch <- batch[[1]]
      
      outputs <- model$model(x_batch)
      batch_predictions <- as.numeric(outputs$cpu())
      
      predictions <- c(predictions, batch_predictions)
    }
  })
  
  if(verbose) {
    cat("âœ… é æ¸¬å®Œæˆ\n")
    cat("  é æ¸¬ç¯„åœ: [", round(min(predictions), 2), ", ", round(max(predictions), 2), "]\n")
    cat("  é æ¸¬å‡å€¼:", round(mean(predictions), 2), "\n")
  }
  
  return(predictions)
}

#' æ‰¹æ¬¡é æ¸¬å‡½æ•¸ (é©ç”¨æ–¼å¤§å‹è³‡æ–™é›†)
#' @param model aqi_lstm_model ç‰©ä»¶
#' @param x_array è¼¸å…¥é™£åˆ— [n_samples, seq_len, n_features]
#' @param batch_size æ‰¹æ¬¡å¤§å°
#' @param verbose æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
#' @return é æ¸¬çµæœå‘é‡
predict_lstm_batch <- function(model, x_array, batch_size = 1000, verbose = TRUE) {
  if(!inherits(model, "aqi_lstm_model")) {
    stop("model å¿…é ˆæ˜¯ aqi_lstm_model ç‰©ä»¶")
  }
  
  if(!is.array(x_array) || length(dim(x_array)) != 3) {
    stop("x_array å¿…é ˆæ˜¯3ç¶­é™£åˆ—")
  }
  
  n_samples <- dim(x_array)[1]
  
  if(verbose) {
    cat("ğŸ”® åŸ·è¡Œæ‰¹æ¬¡é æ¸¬...\n")
    cat("  ç¸½æ¨£æœ¬æ•¸:", format(n_samples, big.mark = ","), "\n")
    cat("  æ‰¹æ¬¡å¤§å°:", format(batch_size, big.mark = ","), "\n")
  }
  
  model$model$eval()
  predictions <- numeric(n_samples)
  n_batches <- ceiling(n_samples / batch_size)
  
  with(torch::no_grad(), {
    for(i in 1:n_batches) {
      start_idx <- (i - 1) * batch_size + 1
      end_idx <- min(i * batch_size, n_samples)
      
      # æå–æ‰¹æ¬¡è³‡æ–™
      batch_x <- x_array[start_idx:end_idx, , , drop = FALSE]
      x_tensor <- torch::torch_tensor(batch_x, dtype = torch::torch_float32())
      x_tensor <- x_tensor$to(device = model$device)
      
      # é æ¸¬
      outputs <- model$model(x_tensor)
      batch_predictions <- as.numeric(outputs$cpu())
      
      predictions[start_idx:end_idx] <- batch_predictions
      
      if(verbose && i %% 10 == 0) {
        cat("  å®Œæˆæ‰¹æ¬¡:", i, "/", n_batches, "\n")
      }
    }
  })
  
  if(verbose) {
    cat("âœ… æ‰¹æ¬¡é æ¸¬å®Œæˆ\n")
  }
  
  return(predictions)
}

# ================================================================================
# 5. æ¨¡å‹å„²å­˜èˆ‡è¼‰å…¥
# ================================================================================

#' å„²å­˜LSTMæ¨¡å‹
#' @param model aqi_lstm_model ç‰©ä»¶
#' @param file_path å„²å­˜è·¯å¾‘ (ä¸å«å‰¯æª”å)
save_lstm_model <- function(model, file_path) {
  if(!inherits(model, "aqi_lstm_model")) {
    stop("model å¿…é ˆæ˜¯ aqi_lstm_model ç‰©ä»¶")
  }
  
  dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
  
  # å„²å­˜å®Œæ•´æ¨¡å‹ç‰©ä»¶ (ä¸åŒ…å«torchæ¨¡å‹)
  model_copy <- model
  model_copy$model <- NULL  # ç§»é™¤torchæ¨¡å‹ä»¥é¿å…åºåˆ—åŒ–å•é¡Œ
  
  model_path <- paste0(file_path, "_model.rds")
  saveRDS(model_copy, model_path)
  
  # å„²å­˜torchæ¨¡å‹ç‹€æ…‹
  torch_path <- paste0(file_path, "_torch.pt")
  torch::torch_save(model$model$state_dict(), torch_path)
  
  # å„²å­˜è¨“ç·´æ­·å²
  history_path <- paste0(file_path, "_history.rds")
  history <- list(
    train_losses = model$train_losses,
    val_losses = model$val_losses,
    best_val_loss = model$best_val_loss
  )
  saveRDS(history, history_path)
  
  cat("âœ… LSTM æ¨¡å‹å·²å„²å­˜:\n")
  cat("  æ¨¡å‹ç‰©ä»¶:", model_path, "\n")
  cat("  Torchç‹€æ…‹:", torch_path, "\n")
  cat("  è¨“ç·´æ­·å²:", history_path, "\n")
}

#' è¼‰å…¥LSTMæ¨¡å‹
#' @param file_path æ¨¡å‹è·¯å¾‘ (ä¸å«å‰¯æª”å)
#' @return aqi_lstm_model ç‰©ä»¶
load_lstm_model <- function(file_path) {
  model_path <- paste0(file_path, "_model.rds")
  torch_path <- paste0(file_path, "_torch.pt")
  
  if(!file.exists(model_path)) {
    stop("æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: ", model_path)
  }
  
  if(!file.exists(torch_path)) {
    stop("Torchç‹€æ…‹æª”æ¡ˆä¸å­˜åœ¨: ", torch_path)
  }
  
  # è¼‰å…¥æ¨¡å‹ç‰©ä»¶
  model <- readRDS(model_path)
  
  if(!inherits(model, "aqi_lstm_model")) {
    stop("è¼‰å…¥çš„ç‰©ä»¶ä¸æ˜¯ aqi_lstm_model é¡å‹")
  }
  
  # é‡å»ºtorchæ¨¡å‹
  torch_model <- create_lstm_model(model$n_features, model$params)
  torch_model <- torch_model$to(device = model$device)
  
  # è¼‰å…¥æ¨¡å‹ç‹€æ…‹
  state_dict <- torch::torch_load(torch_path)
  torch_model$load_state_dict(state_dict)
  
  model$model <- torch_model
  
  cat("âœ… LSTM æ¨¡å‹è¼‰å…¥å®Œæˆ:", model_path, "\n")
  return(model)
}

# ================================================================================
# 6. æ¨¡å‹è¨ºæ–·å‡½æ•¸
# ================================================================================

#' è¨ºæ–·LSTMæ¨¡å‹
#' @param model aqi_lstm_model ç‰©ä»¶
#' @param test_dataset æ¸¬è©¦è³‡æ–™é›†
#' @return è¨ºæ–·çµæœåˆ—è¡¨
diagnose_lstm_model <- function(model, test_dataset = NULL) {
  if(!inherits(model, "aqi_lstm_model")) {
    stop("model å¿…é ˆæ˜¯ aqi_lstm_model ç‰©ä»¶")
  }
  
  diagnosis <- list()
  
  # åŸºæœ¬è³‡è¨Š
  diagnosis$basic_info <- list(
    data_type = model$data_type,
    n_features = model$n_features,
    seq_len = model$seq_len,
    device = model$device,
    training_time = model$training_time
  )
  
  # æ¨¡å‹åƒæ•¸çµ±è¨ˆ
  n_params <- sum(sapply(model$model$parameters, function(p) p$numel()))
  diagnosis$model_stats <- list(
    n_parameters = n_params,
    hidden_size = model$params$hidden_size,
    num_layers = model$params$num_layers,
    dropout = model$params$dropout
  )
  
  # è¨“ç·´æ­·å²
  diagnosis$training_history <- list(
    train_losses = model$train_losses,
    val_losses = model$val_losses,
    best_val_loss = model$best_val_loss,
    n_epochs = length(model$train_losses)
  )
  
  # æ”¶æ–‚æ€§åˆ†æ
  if(length(model$train_losses) > 10) {
    recent_losses <- tail(model$train_losses, 10)
    loss_trend <- lm(recent_losses ~ seq_along(recent_losses))$coefficients[2]
    diagnosis$convergence <- list(
      loss_trend = loss_trend,
      is_converging = loss_trend < 0,
      final_loss = tail(model$train_losses, 1)
    )
  }
  
  # å¦‚æœæä¾›æ¸¬è©¦è³‡æ–™ï¼Œé€²è¡Œé æ¸¬è¨ºæ–·
  if(!is.null(test_dataset)) {
    predictions <- predict_lstm(model, test_dataset, verbose = FALSE)
    evaluation <- evaluate_predictions(test_dataset$y, predictions)
    diagnosis$test_performance <- evaluation
  }
  
  class(diagnosis) <- c("aqi_lstm_diagnosis", "list")
  return(diagnosis)
}

#' æ‰“å°LSTMè¨ºæ–·çµæœ
#' @param x aqi_lstm_diagnosis ç‰©ä»¶
print.aqi_lstm_diagnosis <- function(x, ...) {
  cat("AQI LSTM æ¨¡å‹è¨ºæ–·\n")
  cat("==================\n")
  
  # åŸºæœ¬è³‡è¨Š
  cat("ğŸ“Š åŸºæœ¬è³‡è¨Š:\n")
  cat("  è³‡æ–™é¡å‹:", x$basic_info$data_type, "\n")
  cat("  ç‰¹å¾µæ•¸é‡:", x$basic_info$n_features, "\n")
  cat("  åºåˆ—é•·åº¦:", x$basic_info$seq_len, "\n")
  cat("  è¨­å‚™:", x$basic_info$device, "\n")
  cat("  è¨“ç·´æ™‚é–“:", round(x$basic_info$training_time, 2), "åˆ†é˜\n\n")
  
  # æ¨¡å‹çµ±è¨ˆ
  cat("ğŸ§  æ¨¡å‹çµ±è¨ˆ:\n")
  cat("  åƒæ•¸æ•¸é‡:", format(x$model_stats$n_parameters, big.mark = ","), "\n")
  cat("  éš±è—å±¤å¤§å°:", x$model_stats$hidden_size, "\n")
  cat("  LSTMå±¤æ•¸:", x$model_stats$num_layers, "\n")
  cat("  Dropout:", x$model_stats$dropout, "\n\n")
  
  # è¨“ç·´æ­·å²
  cat("ğŸ“ˆ è¨“ç·´æ­·å²:\n")
  cat("  è¨“ç·´è¼ªæ•¸:", x$training_history$n_epochs, "\n")
  cat("  æœ€çµ‚è¨“ç·´æå¤±:", round(tail(x$training_history$train_losses, 1), 6), "\n")
  if(length(x$training_history$val_losses) > 0) {
    cat("  æœ€çµ‚é©—è­‰æå¤±:", round(tail(x$training_history$val_losses, 1), 6), "\n")
    cat("  æœ€ä½³é©—è­‰æå¤±:", round(x$training_history$best_val_loss, 6), "\n")
  }
  
  # æ”¶æ–‚æ€§åˆ†æ
  if(!is.null(x$convergence)) {
    cat("\nğŸ¯ æ”¶æ–‚æ€§åˆ†æ:\n")
    cat("  æå¤±è¶¨å‹¢:", ifelse(x$convergence$is_converging, "æ”¶æ–‚", "ç™¼æ•£"), "\n")
    cat("  è¶¨å‹¢æ–œç‡:", round(x$convergence$loss_trend, 8), "\n")
  }
  
  # æ¸¬è©¦æ€§èƒ½
  if(!is.null(x$test_performance)) {
    cat("\nğŸ¯ æ¸¬è©¦é›†æ€§èƒ½:\n")
    cat("  RMSE:", round(x$test_performance$rmse, 4), "\n")
    cat("  MAE:", round(x$test_performance$mae, 4), "\n")
    cat("  RÂ²:", round(x$test_performance$r2, 4), "\n")
  }
}

# ================================================================================
# 7. å¯¦ç”¨å·¥å…·å‡½æ•¸
# ================================================================================

#' æ¸…ç†GPUè¨˜æ†¶é«”
clear_gpu_memory <- function() {
  if(torch::cuda_is_available()) {
    torch::cuda_empty_cache()
    gc()
    cat("âœ… GPUè¨˜æ†¶é«”å·²æ¸…ç†\n")
  }
}

#' æª¢æŸ¥GPUè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
check_gpu_memory <- function() {
  if(torch::cuda_is_available()) {
    allocated <- torch::cuda_memory_allocated() / 1024^3
    reserved <- torch::cuda_memory_reserved() / 1024^3
    
    cat("GPUè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³:\n")
    cat("  å·²åˆ†é…:", round(allocated, 2), "GB\n")
    cat("  å·²ä¿ç•™:", round(reserved, 2), "GB\n")
    
    return(list(allocated = allocated, reserved = reserved))
  } else {
    cat("CUDAä¸å¯ç”¨\n")
    return(NULL)
  }
}

cat("âœ… LSTM æ¨¡å‹æ¨¡çµ„è¼‰å…¥å®Œæˆ\n") 