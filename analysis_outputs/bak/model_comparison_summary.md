# Model Comparison Analysis Report

## ğŸ† æ•´é«”æœ€ä½³æ¨¡å‹ (Top 10)

|model_id                                                      |model_type |dataset_type | test_rmse| model_size_mb|
|:-------------------------------------------------------------|:----------|:------------|---------:|-------------:|
|lgbm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |lgbm       |separate     |    0.0538|         32.88|
|lgbm_separate_norm_Nomorlization_æ–—å…­_C0K400_combined_windows |lgbm       |separate     |    0.0604|         35.49|
|lgbm_separate_norm_Nomorlization_å®‰å—_467420_combined_windows |lgbm       |separate     |    0.0606|         34.28|
|lstm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |lstm       |separate     |    0.0611|          0.07|
|lgbm_separate_norm_Nomorlization_åŸ”é‡Œ_C0H890_combined_windows |lgbm       |separate     |    0.0613|         32.39|
|lstm_separate_norm_Nomorlization_æ–—å…­_C0K400_combined_windows |lstm       |separate     |    0.0614|          0.07|
|lgbm_separate_norm_Nomorlization_å—æŠ•_C0I460_combined_windows |lgbm       |separate     |    0.0636|         35.28|
|lstm_separate_norm_Nomorlization_åŸ”é‡Œ_C0H890_combined_windows |lstm       |separate     |    0.0653|          0.07|
|lstm_separate_norm_Nomorlization_å—æŠ•_C0I460_combined_windows |lstm       |separate     |    0.0658|          0.07|
|lgbm_separate_norm_Nomorlization_å±æ±_C0R570_combined_windows |lgbm       |separate     |    0.0658|         34.93|

## ğŸ“Š æ¨¡å‹é¡å‹ vs è³‡æ–™é¡å‹æ¯”è¼ƒ

|dataset_type |model_type | best_rmse| worst_rmse| avg_rmse| model_count|best_model                                                    | avg_size_mb|
|:------------|:----------|---------:|----------:|--------:|-----------:|:-------------------------------------------------------------|-----------:|
|separate     |lgbm       |    0.0538|     3.7511|   1.7879|         121|lgbm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |     35.1252|
|separate     |lstm       |    0.0611|     3.8748|   1.7912|         122|lstm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |      0.0701|
|combine      |lgbm       |    0.0759|     2.8958|   1.4125|           6|lgbm_combine_norm_chunk_02                                    |    126.3433|
|combine      |lstm       |    0.1031|    16.4426|   7.3040|           6|lstm_combine_norm_chunk_02                                    |      0.0700|

## ğŸ¯ å„è³‡æ–™é¡å‹æœ€ä½³è¡¨ç¾

|dataset_type | best_rmse| model_count|best_model_type |best_model_id                                                 |
|:------------|---------:|-----------:|:---------------|:-------------------------------------------------------------|
|separate     |    0.0538|         243|lgbm            |lgbm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |
|combine      |    0.0759|          12|lgbm            |lgbm_combine_norm_chunk_02                                    |

## ğŸ“ˆ é—œéµæ´å¯Ÿ

- **æœ€ä½³æ•´é«”æ¨¡å‹**: lgbm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows (RMSE: 0.0538)
- **æ¨¡å‹é¡å‹çµ±è¨ˆ**:
  - LightGBM æ¨¡å‹æ•¸é‡: 127
  - LSTM æ¨¡å‹æ•¸é‡: 128
- **è³‡æ–™é¡å‹çµ±è¨ˆ**:
  - Combine è³‡æ–™é¡å‹æœ€ä½³ RMSE: 0.0759
  - Separate è³‡æ–™é¡å‹æœ€ä½³ RMSE: 0.0538

**åˆ†æå®Œæˆæ™‚é–“:** 2025-06-16 20:59:17.604681
