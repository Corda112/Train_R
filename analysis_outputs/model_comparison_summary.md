# Model Comparison Analysis Report

## ğŸ† æ•´é«”æœ€ä½³æ¨¡å‹ (Top 10)

|model_id                                                      |model_type |dataset_type | test_rmse| model_size_mb|
|:-------------------------------------------------------------|:----------|:------------|---------:|-------------:|
|lstm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |lstm       |separate     |    0.0611|          0.07|
|lstm_separate_norm_Nomorlization_æ–—å…­_C0K400_combined_windows |lstm       |separate     |    0.0614|          0.07|
|lstm_separate_norm_Nomorlization_åŸ”é‡Œ_C0H890_combined_windows |lstm       |separate     |    0.0653|          0.07|
|lstm_separate_norm_Nomorlization_å—æŠ•_C0I460_combined_windows |lstm       |separate     |    0.0658|          0.07|
|lstm_separate_norm_Nomorlization_ä»æ­¦_C0V680_combined_windows |lstm       |separate     |    0.0723|          0.07|
|lstm_separate_norm_Nomorlization_ç¾æ¿ƒ_72V140_combined_windows |lstm       |separate     |    0.0731|          0.07|
|lstm_separate_norm_Nomorlization_æœ´å­_C0M650_combined_windows |lstm       |separate     |    0.0734|          0.07|
|lstm_separate_norm_Nomorlization_å®‰å—_467420_combined_windows |lstm       |separate     |    0.0740|          0.07|
|lstm_separate_norm_Nomorlization_å±æ±_C0R570_combined_windows |lstm       |separate     |    0.0745|          0.07|
|lstm_separate_norm_Nomorlization_å¤§é‡Œ_C0F9N0_combined_windows |lstm       |separate     |    0.0767|          0.07|

## ğŸ“Š æ¨¡å‹é¡å‹ vs è³‡æ–™é¡å‹æ¯”è¼ƒ

|dataset_type |model_type | best_rmse| worst_rmse| avg_rmse| model_count|best_model                                                    | avg_size_mb|
|:------------|:----------|---------:|----------:|--------:|-----------:|:-------------------------------------------------------------|-----------:|
|separate     |lstm       |    0.0611|     0.1168|   0.0851|          27|lstm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |        0.07|
|combine      |lstm       |    0.1031|     0.1203|   0.1120|           3|lstm_combine_norm_chunk_02                                    |        0.07|

## ğŸ¯ å„è³‡æ–™é¡å‹æœ€ä½³è¡¨ç¾

|dataset_type | best_rmse| model_count|best_model_type |best_model_id                                                 |
|:------------|---------:|-----------:|:---------------|:-------------------------------------------------------------|
|separate     |    0.0611|          27|lstm            |lstm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows |
|combine      |    0.1031|           3|lstm            |lstm_combine_norm_chunk_02                                    |

## ğŸ“ˆ é—œéµæ´å¯Ÿ

- **æœ€ä½³æ•´é«”æ¨¡å‹**: lstm_separate_norm_Nomorlization_ç«¹å±±_U2HA50_combined_windows (RMSE: 0.0611)
- **æ¨¡å‹é¡å‹çµ±è¨ˆ**:
  - LightGBM æ¨¡å‹æ•¸é‡: 0
  - LSTM æ¨¡å‹æ•¸é‡: 30
- **è³‡æ–™é¡å‹çµ±è¨ˆ**:
  - Combine è³‡æ–™é¡å‹æœ€ä½³ RMSE: 0.1031
  - Separate è³‡æ–™é¡å‹æœ€ä½³ RMSE: 0.0611

**åˆ†æå®Œæˆæ™‚é–“:** 2025-06-17 01:09:23.267673
