# AQI滑動窗口資料產生系統 - 快速操作指南

## 🚀 快速開始

### 1. 系統執行
```bash
# 生產環境執行 (建議)
nohup Rscript generate_sliding_windows_production.R > output.log 2>&1 &

# 直接執行 (測試用)
Rscript generate_sliding_windows_production.R
```

### 2. 進度監控
```bash
# 檢查進度
Get-ChildItem sliding_windows_production/progress/*.flag | Measure-Object

# 檢查輸出
Get-ChildItem sliding_windows_production/*/*.rds | Measure-Object
```

### 3. 驗證結果
```bash
# 執行完整驗證
Rscript 驗證和使用範例.R
```

---

## 📊 系統狀態總覽

**✅ 處理完成狀態 (2025年6月)**
- **小檔案**: 150/150 成功 (100%)
  - Separate: 75個檔案 ✅
  - Separate_Normalization: 75個檔案 ✅
- **大檔案**: 2/2 成功 (100%)
  - Combine: 17個區塊 + 索引 ✅
  - Combine_Normalization: 17個區塊 + 索引 ✅

**📈 資料統計**
- **總窗口數**: ~650萬個
- **總檔案數**: 186個
- **總大小**: 227.3 MB (壓縮後)
- **處理時間**: ~4-6小時 (完整資料集)

---

## 💾 資料使用方法

### 讀取小檔案 (分站資料)
```r
# 讀取單一站點
w <- readRDS('sliding_windows_production/Separate/二林_C0G730_combined_windows.rds')
X <- w$X_raw  # [43512, 72, 27] - 窗口數 x 時間步 x 特徵數
y <- w$y_raw  # [43512] - 目標AQI值

# 批次讀取所有站點
source('驗證和使用範例.R')
data <- load_all_small_files("separate")
```

### 讀取大檔案 (合併資料)
```r
# 讀取索引
idx <- readRDS('sliding_windows_production/Combine/Combine_AllData_index.rds')
cat("總窗口數:", format(idx$total_windows, big.mark=","))  # 3,268,728

# 逐區塊處理
for(chunk_file in idx$chunk_files) {
  chunk_path <- file.path(idx$output_dir, chunk_file)
  w <- readRDS(chunk_path)
  
  # 處理當前區塊 (~20萬窗口)
  X_chunk <- w$X_raw  # [n_windows, 72, 104]
  y_chunk <- w$y_raw  # [n_windows]
  
  # 您的模型訓練代碼
  # model <- train_model(X_chunk, y_chunk)
}
```

---

## 🔧 核心參數說明

### 滑動窗口配置
```r
input_seq_len   <- 72    # 輸入序列: 72小時 (3天)
output_horizon  <- 1     # 預測範圍: 1小時
stride          <- 1     # 滑動步長: 1筆
target          <- "AQI_aqi"  # 預測目標
```

### 記憶體管理
```r
MAX_WINDOWS_PER_FILE <- 1000000  # 單檔最大窗口數 (64GB RAM)
chunk_size           <- 200000   # 大檔分塊大小 (20萬筆)
overlap              <- 72       # 區塊重疊確保連續性
```

---

## 📁 輸出結構說明

```
sliding_windows_production/
├── Separate/                    # 75個分站原始窗口檔案
│   ├── 二林_C0G730_combined_windows.rds
│   ├── 三義_C0G740_combined_windows.rds
│   └── ...
├── Separate_Normalization/      # 75個分站標準化窗口檔案
│   ├── 二林_C0G730_combined_windows.rds
│   └── ...
├── Combine/                     # 合併原始資料 (17個區塊)
│   ├── Combine_AllData_chunk01.rds
│   ├── Combine_AllData_chunk02.rds
│   ├── ...
│   └── Combine_AllData_index.rds
├── Combine_Normalization/       # 合併標準化資料 (17個區塊)
│   ├── Nomorlization_Combine_AllData_chunk01.rds
│   ├── ...
│   └── Nomorlization_Combine_AllData_index.rds
└── progress/                    # 進度追蹤檔案
    ├── 二林_C0G730_combined.flag
    └── ...
```

---

## ⚡ 效能基準

### 讀取速度 (64GB RAM環境)
- **小檔案**: ~100K 窗口/秒
- **大檔案區塊**: ~19K 窗口/秒
- **索引檔案**: <0.001秒

### 記憶體使用
- **小檔案處理**: 峰值 ~2GB
- **大檔案處理**: 峰值 ~20-25GB
- **並行處理**: 額外 ~8GB

---

## 🎯 最佳實踐

### 1. 生產環境使用
```bash
# 背景執行並記錄日誌
nohup Rscript generate_sliding_windows_production.R > aqi_processing.log 2>&1 &

# 監控進度
tail -f aqi_processing.log
```

### 2. 模型訓練建議
```r
# 小檔案: 適合站點特定模型
for(station_file in station_files) {
  w <- readRDS(station_file)
  model <- train_station_model(w$X_raw, w$y_raw)
}

# 大檔案: 適合全域模型
idx <- readRDS('sliding_windows_production/Combine/Combine_AllData_index.rds')
for(chunk_file in idx$chunk_files) {
  w <- readRDS(file.path(idx$output_dir, chunk_file))
  model <- update_global_model(model, w$X_raw, w$y_raw)
}
```

### 3. 記憶體優化
```r
# 處理完立即清理
w <- readRDS(chunk_path)
# ... 處理資料 ...
rm(w); gc()  # 釋放記憶體
```

---

## 📞 故障排除

### 常見問題
1. **記憶體不足**: 降低 `MAX_WINDOWS_PER_FILE` 或 `chunk_size`
2. **檔案路徑錯誤**: 檢查 `DATA_DIRS` 設定中的大小寫
3. **Arrow套件問題**: 設定 `arrow_available <- FALSE` 使用純R處理

### 驗證命令
```r
# 檢查系統完整性
source('驗證和使用範例.R')
verify_system_output()

# 檢查資料品質
check_data_quality()

# 效能測試
benchmark_performance()
```

---

**系統版本**: 生產級最終版 v1.0  
**相容性**: R 4.0+, Windows/Linux  
**建議配置**: 64GB RAM, 多核心CPU 